{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "```\n",
    "pytorch\n",
    "pytorch-lightning\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        r\"\"\"\n",
    "        inputs: sample images\n",
    "        \"\"\"\n",
    "        inputs = inputs.view(-1, 28*28)\n",
    "        return self.layers(inputs)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator\"\"\"\n",
    "    def __init__(self, latent_dim):\n",
    "      super(Generator, self).__init__()\n",
    "      self.layers = nn.Sequential(\n",
    "        nn.Linear(in_features=latent_dim, out_features=256),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Linear(in_features=256, out_features=512),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Linear(in_features=512, out_features=1024),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Linear(in_features=1024, out_features=28*28),\n",
    "        nn.Tanh())\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        r\"\"\"\n",
    "        inputs: random values from prior, z\n",
    "        \"\"\"\n",
    "        return self.layers(inputs).view(-1, 1, 28, 28)\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        r\"\"\"\n",
    "        Code Reference: PyTorch-Lightining https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=ArrPXFM371jR\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.D = Discriminator()\n",
    "        self.G = Generator(self.hparams.latent_dim)\n",
    "        # cache\n",
    "        self.generated_imgs = None\n",
    "        self.last_imgs = None\n",
    "    def forward(self, z):\n",
    "        return self.G(z)\n",
    "\n",
    "    def criterion(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        x, _ = batch\n",
    "        bs = x.size(0)\n",
    "        self.last_imgs = x\n",
    "        # training G\n",
    "        if optimizer_idx == 0:  \n",
    "            z = torch.randn(bs, self.hparams.latent_dim)\n",
    "            if self.on_gpu:\n",
    "                z = z.to(x.device)\n",
    "            self.generated_imgs = self(z)\n",
    "\n",
    "            valid_label = torch.ones(bs, 1)\n",
    "            if self.on_gpu:\n",
    "              valid_label = valid_label.to(x.device)\n",
    "\n",
    "            # Pass the generated inputs to Discriminator\n",
    "            # Let the Generator learn how to make a good faked images\n",
    "            g_loss = self.criterion(self.D(self.generated_imgs), valid_label)\n",
    "            tqdm_dict = {'g_loss': g_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': g_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "        # training D\n",
    "        if optimizer_idx == 1:\n",
    "            valid_label = torch.ones(bs, 1)\n",
    "            if self.on_gpu:\n",
    "                valid_label = valid_label.to(x.device)\n",
    "\n",
    "            # Pass the real inputs to Discriminator\n",
    "            # Let the Discriminator learn to determine whether inputs are real \n",
    "            real_loss = self.criterion(self.D(x), valid_label)\n",
    "\n",
    "            fake_label = torch.zeros(bs, 1)\n",
    "            if self.on_gpu:\n",
    "              fake_label = fake_label.to(x.device)\n",
    "\n",
    "            # Pass the cached generated image\n",
    "            fake_loss = self.criterion(self.D(self.generated_imgs.detach()), fake_label)\n",
    "\n",
    "            # Discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': d_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2\n",
    "\n",
    "        G_optimizer = optim.Adam(self.G.parameters(), lr=lr, betas=(b1, b2))\n",
    "        D_optimizer = optim.Adam(self.D.parameters(), lr=lr, betas=(b1, b2))\n",
    "        return [G_optimizer, D_optimizer], []\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        root_dir = Path(\".\").absolute().parent.parent\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.5], [0.5])])\n",
    "        dataset = MNIST(\n",
    "            root_dir / \"data\", \n",
    "            train=True, \n",
    "            download=True, \n",
    "            transform=transform\n",
    "        )\n",
    "        loader = DataLoader(dataset, batch_size=hparams.batch_size, shuffle=True)\n",
    "        return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'batch_size': 32,\n",
    "    'lr': 0.0002,\n",
    "    'b1': 0.5,\n",
    "    'b2': 0.999,\n",
    "    'latent_dim': 50\n",
    "}\n",
    "hparams = Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "GPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nCUDA_VISIBLE_DEVICES: [0]\n\n  | Name | Type          | Params\n---------------------------------------\n0 | D    | Discriminator | 1 M   \n1 | G    | Generator     | 1 M   \nEpoch 5: 100%|██████████| 1875/1875 [00:25<00:00, 74.54it/s, loss=0.941, v_num=0, g_loss=0.994, d_loss=0.647]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "gan_model = GAN(hparams)\n",
    "\n",
    "# most basic trainer, uses good defaults (1 gpu)\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=1)    \n",
    "trainer.fit(gan_model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dict = {\n",
    "    f\"L{i}\": widgets.IntSlider(\n",
    "        min=0, max=99, step=1, value=0, description=f\"L{i}\"\n",
    "    ) for i in range(hparams.latent_dim)\n",
    "}\n",
    "ui = widgets.VBox(\n",
    "    list(latent_dict.values()), \n",
    "    layout=widgets.Layout(display='inline-flex', flex_flow='column', border='solid 2px', justify_content='space-between')\n",
    ")\n",
    "z = torch.zeros(hparams.latent_dim)\n",
    "zz = torch.linspace(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img(L0, L1, L2, L3, L4, L5, L6, L7, L8, L9):\n",
    "    for i in range(hparams.latent_dim):\n",
    "        idx = latent_dict[f\"L{i}\"].value\n",
    "        z[i] = zz[idx]\n",
    "    output = gan_model(z).squeeze().numpy()\n",
    "    plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img(**kwargs):\n",
    "    for i in range(hparams.latent_dim):\n",
    "        idx = kwargs[f\"L{i}\"]\n",
    "        z[i] = zz[idx]\n",
    "    output = gan_model(z).squeeze().numpy()\n",
    "    plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.interactive_output(generate_img, latent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(IntSlider(value=0, description='L0', max=99), IntSlider(value=0, description='L1', max=99), Int…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9d39c65f7ac4391add6d31b54ab16a4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<Figure size 432x288 with 1 Axes>', 'i…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbe2baaf1fd8458ca6cf2670c4d65927"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}