{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "```\n",
    "pytorch\n",
    "pytorch-lightning\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\miniconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:25: UserWarning: Unsupported `ReduceOp` for distributed computing.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        r\"\"\"\n",
    "        inputs: sample images\n",
    "        \"\"\"\n",
    "        inputs = inputs.view(-1, 28*28)\n",
    "        return self.layers(inputs)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator\"\"\"\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=latent_dim, out_features=256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=1024, out_features=28*28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        r\"\"\"\n",
    "        inputs: random values from prior, z\n",
    "        \"\"\"\n",
    "        return self.layers(inputs).view(-1, 1, 28, 28)\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        r\"\"\"\n",
    "        Code Reference: PyTorch-Lightining https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=ArrPXFM371jR\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.D = Discriminator()\n",
    "        self.G = Generator(self.hparams.latent_dim)\n",
    "        # cache\n",
    "        self.generated_imgs = None\n",
    "        self.last_imgs = None\n",
    "    def forward(self, z):\n",
    "        return self.G(z)\n",
    "\n",
    "    def criterion(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        x, _ = batch\n",
    "        bs = x.size(0)\n",
    "        self.last_imgs = x\n",
    "        # training G\n",
    "        if optimizer_idx == 0:  \n",
    "            z = torch.randn(bs, self.hparams.latent_dim)\n",
    "            if self.on_gpu:\n",
    "                z = z.to(x.device)\n",
    "            self.generated_imgs = self(z)\n",
    "\n",
    "            valid_label = torch.ones(bs, 1)\n",
    "            if self.on_gpu:\n",
    "                valid_label = valid_label.to(x.device)\n",
    "\n",
    "            # Pass the generated inputs to Discriminator\n",
    "            # Let the Generator learn how to make a good faked images\n",
    "            g_loss = self.criterion(self.D(self.generated_imgs), valid_label)\n",
    "            tqdm_dict = {'g_loss': g_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': g_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "        # training D\n",
    "        if optimizer_idx == 1:\n",
    "            valid_label = torch.ones(bs, 1)\n",
    "            if self.on_gpu:\n",
    "                valid_label = valid_label.to(x.device)\n",
    "\n",
    "            # Pass the real inputs to Discriminator\n",
    "            # Let the Discriminator learn to determine whether inputs are real \n",
    "            real_loss = self.criterion(self.D(x), valid_label)\n",
    "\n",
    "            fake_label = torch.zeros(bs, 1)\n",
    "            if self.on_gpu:\n",
    "                fake_label = fake_label.to(x.device)\n",
    "\n",
    "            # Pass the cached generated image\n",
    "            fake_loss = self.criterion(self.D(self.generated_imgs.detach()), fake_label)\n",
    "\n",
    "            # Discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': d_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2\n",
    "\n",
    "        G_optimizer = optim.Adam(self.G.parameters(), lr=lr, betas=(b1, b2))\n",
    "        D_optimizer = optim.Adam(self.D.parameters(), lr=lr, betas=(b1, b2))\n",
    "        return [G_optimizer, D_optimizer], []\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        root_dir = Path(\".\").absolute().parent.parent\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.5], [0.5])])\n",
    "        dataset = MNIST(\n",
    "            root_dir / \"data\", \n",
    "            train=True, \n",
    "            download=True, \n",
    "            transform=transform\n",
    "        )\n",
    "        loader = DataLoader(dataset, batch_size=hparams.batch_size, shuffle=True)\n",
    "        return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.0002,\n",
    "    'b1': 0.5,\n",
    "    'b2': 0.999,\n",
    "    'latent_dim': 5\n",
    "}\n",
    "hparams = Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\miniconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:25: UserWarning: Checkpoint directory C:\\Users\\simon\\Desktop\\Codes\\PaperCode\\papers\\GAN\\ckpts exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "ckpts_path = str(Path(\".\").absolute() / \"ckpts\")\n",
    "# DEFAULTS used by the Trainer\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=ckpts_path,\n",
    "    save_last=True,\n",
    "    verbose=True,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | D    | Discriminator | 1 M   \n",
      "1 | G    | Generator     | 1 M   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef3ddb58ac64efda73f4c2daf080880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\miniconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:25: RuntimeWarning: The metric you returned None must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_loss in validation_epoch_end()?\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\simon\\miniconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:25: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_model = GAN(hparams)\n",
    "\n",
    "# most basic trainer, uses good defaults (1 gpu)\n",
    "trainer = pl.Trainer(max_epochs=15, gpus=1, checkpoint_callback=checkpoint_callback)    \n",
    "trainer.fit(gan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(ckpts_path + \"/last.ckpt\")\n",
    "G_weight = OrderedDict({k.lstrip(\"G.\"): v for k, v in ckpt[\"state_dict\"].items() if \"G.\" in k})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(latent_dim=hparams.latent_dim)\n",
    "generator.load_state_dict(G_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dict = {\n",
    "    f\"L{i}\": widgets.IntSlider(\n",
    "        min=0, max=99, step=1, value=0, description=f\"L{i}\"\n",
    "    ) for i in range(hparams.latent_dim)\n",
    "}\n",
    "ui = widgets.VBox(\n",
    "    list(latent_dict.values()), \n",
    "    layout=widgets.Layout(display='inline-flex', flex_flow='column', border='solid 2px', justify_content='space-between')\n",
    ")\n",
    "z = torch.zeros(hparams.latent_dim)\n",
    "zz = torch.linspace(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img(L0, L1, L2, L3, L4):\n",
    "    for i in range(hparams.latent_dim):\n",
    "        idx = latent_dict[f\"L{i}\"].value\n",
    "        z[i] = zz[idx]\n",
    "    output = generator(z).detach().squeeze().numpy()\n",
    "    plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.interactive_output(generate_img, latent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faec2f31a7b4ae3a83b1af475b3c3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=0, description='L0', max=99), IntSlider(value=0, description='L1', max=99), Int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1e35e5ff784a7c84a29c689b8cf191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<Figure size 432x288 with 1 Axes>', 'i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
